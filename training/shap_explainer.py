"""
SHAP Explainer for Ethical Eye Extension
Research Project: Explainable AI for Dark Pattern Detection

This module implements SHAP-based explanations for dark pattern detection
to provide transparency and user education.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import torch
from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast
import json
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class EthicalEyeSHAPExplainer:
    """SHAP Explainer for Ethical Eye model"""
    
    def __init__(self, model_path='models/ethical_eye/final_model'):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.explainer = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Load model and tokenizer
        self.load_model()
        
        # Initialize SHAP explainer
        self.initialize_shap_explainer()
        
        # Create output directories
        os.makedirs('plots/research/shap', exist_ok=True)
        os.makedirs('results/shap', exist_ok=True)
    
    def load_model(self):
        """Load the trained DistilBERT model"""
        print("Loading trained model...")
        
        self.model = DistilBertForSequenceClassification.from_pretrained(self.model_path)
        self.tokenizer = DistilBertTokenizerFast.from_pretrained(self.model_path)
        
        self.model.to(self.device)
        self.model.eval()
        
        print(f"Model loaded successfully!")
        print(f"Number of labels: {self.model.config.num_labels}")
        print(f"Labels: {list(self.model.config.id2label.values())}")
    
    def initialize_shap_explainer(self):
        """Initialize SHAP explainer"""
        print("Initializing SHAP explainer...")
        
        # Create a wrapper function for the model
        def model_wrapper(texts):
            """Wrapper function for SHAP explainer"""
            if isinstance(texts, str):
                texts = [texts]
            
            # Tokenize inputs
            inputs = self.tokenizer(
                texts,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=512
            )
            
            # Move to device
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # Get predictions
            with torch.no_grad():
                outputs = self.model(**inputs)
                probabilities = torch.softmax(outputs.logits, dim=-1)
            
            return probabilities.cpu().numpy()
        
        # Initialize SHAP explainer
        self.explainer = shap.Explainer(model_wrapper, self.tokenizer)
        
        print("SHAP explainer initialized successfully!")
    
    def explain_text(self, text, top_k=5):
        """Generate SHAP explanation for a single text"""
        print(f"Generating SHAP explanation for: '{text[:50]}...'")
        
        # Get SHAP values
        shap_values = self.explainer([text])
        
        # Get tokens
        tokens = self.tokenizer.tokenize(text)
        
        # Get feature importance scores
        feature_importance = shap_values.values[0]
        
        # Get top contributing words
        top_words = self.get_top_contributing_words(tokens, feature_importance, top_k)
        
        # Get prediction
        prediction = self.model_wrapper([text])
        predicted_class = np.argmax(prediction[0])
        confidence = np.max(prediction[0])
        
        # Generate explanation
        explanation = self.generate_human_readable_explanation(
            text, top_words, predicted_class, confidence
        )
        
        return {
            'text': text,
            'predicted_class': self.model.config.id2label[predicted_class],
            'confidence': float(confidence),
            'top_words': top_words,
            'explanation': explanation,
            'shap_values': shap_values.values[0].tolist(),
            'tokens': tokens
        }
    
    def get_top_contributing_words(self, tokens, shap_values, top_k=5):
        """Get top contributing words from SHAP values"""
        # Create word-score pairs
        word_scores = list(zip(tokens, shap_values))
        
        # Sort by absolute SHAP value
        word_scores.sort(key=lambda x: abs(x[1]), reverse=True)
        
        # Return top k words
        return word_scores[:top_k]
    
    def generate_human_readable_explanation(self, text, top_words, predicted_class, confidence):
        """Generate human-readable explanation"""
        pattern_descriptions = {
            'Urgency': 'Creates false time pressure to rush decisions',
            'Scarcity': 'Makes products appear limited in availability',
            'Social Proof': 'Uses fake social validation to influence behavior',
            'Misdirection': 'Deceptively guides users toward unintended actions',
            'Forced Action': 'Requires unnecessary tasks to complete simple actions',
            'Obstruction': 'Makes actions unnecessarily difficult',
            'Sneaking': 'Hides or obscures important information',
            'Hidden Costs': 'Conceals additional fees or charges',
            'Not Dark Pattern': 'Normal, non-manipulative content'
        }
        
        # Get pattern description
        pattern_desc = pattern_descriptions.get(predicted_class, 'Unknown pattern type')
        
        # Get top words
        top_word_list = [word for word, score in top_words]
        
        # Generate explanation
        if predicted_class == 'Not Dark Pattern':
            explanation = f"This text appears to be normal content with {confidence:.1%} confidence."
        else:
            explanation = f"This text is classified as '{predicted_class}' with {confidence:.1%} confidence. "
            explanation += f"{pattern_desc}. "
            explanation += f"Key indicators include: {', '.join(top_word_list)}."
        
        return explanation
    
    def analyze_dataset(self, texts, max_samples=100):
        """Analyze a dataset of texts with SHAP explanations"""
        print(f"Analyzing {min(len(texts), max_samples)} texts...")
        
        results = []
        for i, text in enumerate(texts[:max_samples]):
            if i % 10 == 0:
                print(f"Processing text {i+1}/{min(len(texts), max_samples)}")
            
            try:
                explanation = self.explain_text(text)
                results.append(explanation)
            except Exception as e:
                print(f"Error processing text {i+1}: {e}")
                continue
        
        return results
    
    def create_shap_plots(self, explanations, save_plots=True):
        """Create SHAP visualization plots"""
        print("Creating SHAP visualization plots...")
        
        # 1. Feature Importance Summary
        self.plot_feature_importance_summary(explanations)
        
        # 2. Word Cloud of Important Features
        self.plot_word_cloud(explanations)
        
        # 3. Confidence Distribution
        self.plot_confidence_distribution(explanations)
        
        # 4. Pattern Type Distribution
        self.plot_pattern_distribution(explanations)
        
        # 5. SHAP Values Heatmap
        self.plot_shap_heatmap(explanations)
        
        if save_plots:
            print("SHAP plots saved in plots/research/shap/")
    
    def plot_feature_importance_summary(self, explanations):
        """Plot feature importance summary"""
        plt.figure(figsize=(14, 8))
        
        # Collect all top words and their scores
        all_words = {}
        for exp in explanations:
            for word, score in exp['top_words']:
                if word in all_words:
                    all_words[word] += abs(score)
                else:
                    all_words[word] = abs(score)
        
        # Sort by importance
        sorted_words = sorted(all_words.items(), key=lambda x: x[1], reverse=True)[:20]
        
        words, scores = zip(*sorted_words)
        
        # Create horizontal bar plot
        y_pos = np.arange(len(words))
        bars = plt.barh(y_pos, scores, color=plt.cm.viridis(np.linspace(0, 1, len(words))))
        
        plt.yticks(y_pos, words)
        plt.xlabel('SHAP Value (Cumulative Importance)', fontsize=12)
        plt.title('Top 20 Most Important Words for Dark Pattern Detection', 
                 fontsize=16, fontweight='bold')
        
        # Add value labels
        for i, (bar, score) in enumerate(zip(bars, scores)):
            plt.text(score + 0.01, bar.get_y() + bar.get_height()/2,
                    f'{score:.3f}', ha='left', va='center', fontweight='bold')
        
        plt.grid(True, alpha=0.3, axis='x')
        plt.tight_layout()
        plt.savefig('plots/research/shap/feature_importance_summary.png', 
                   dpi=300, bbox_inches='tight')
        plt.savefig('plots/research/shap/feature_importance_summary.pdf', 
                   bbox_inches='tight')
        plt.close()
    
    def plot_word_cloud(self, explanations):
        """Plot word cloud of important features"""
        try:
            from wordcloud import WordCloud
            
            # Collect all top words
            all_words = []
            for exp in explanations:
                for word, score in exp['top_words']:
                    # Add word multiple times based on importance
                    weight = int(abs(score) * 100)
                    all_words.extend([word] * weight)
            
            # Create word cloud
            wordcloud = WordCloud(
                width=800, height=400,
                background_color='white',
                max_words=100,
                colormap='viridis'
            ).generate(' '.join(all_words))
            
            plt.figure(figsize=(12, 6))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.title('Word Cloud of Important Features for Dark Pattern Detection',
                     fontsize=16, fontweight='bold')
            plt.tight_layout()
            plt.savefig('plots/research/shap/word_cloud.png', dpi=300, bbox_inches='tight')
            plt.savefig('plots/research/shap/word_cloud.pdf', bbox_inches='tight')
            plt.close()
            
        except ImportError:
            print("WordCloud not available. Skipping word cloud plot.")
    
    def plot_confidence_distribution(self, explanations):
        """Plot confidence score distribution"""
        plt.figure(figsize=(12, 6))
        
        confidences = [exp['confidence'] for exp in explanations]
        
        plt.hist(confidences, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        plt.xlabel('Confidence Score', fontsize=12)
        plt.ylabel('Frequency', fontsize=12)
        plt.title('Distribution of Model Confidence Scores', fontsize=16, fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # Add statistics
        mean_conf = np.mean(confidences)
        std_conf = np.std(confidences)
        plt.axvline(mean_conf, color='red', linestyle='--', 
                   label=f'Mean: {mean_conf:.3f}')
        plt.axvline(mean_conf + std_conf, color='orange', linestyle='--', 
                   label=f'+1σ: {mean_conf + std_conf:.3f}')
        plt.axvline(mean_conf - std_conf, color='orange', linestyle='--', 
                   label=f'-1σ: {mean_conf - std_conf:.3f}')
        
        plt.legend()
        plt.tight_layout()
        plt.savefig('plots/research/shap/confidence_distribution.png', 
                   dpi=300, bbox_inches='tight')
        plt.savefig('plots/research/shap/confidence_distribution.pdf', 
                   bbox_inches='tight')
        plt.close()
    
    def plot_pattern_distribution(self, explanations):
        """Plot pattern type distribution"""
        plt.figure(figsize=(12, 8))
        
        # Count pattern types
        pattern_counts = {}
        for exp in explanations:
            pattern = exp['predicted_class']
            pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1
        
        # Create pie chart
        labels = list(pattern_counts.keys())
        sizes = list(pattern_counts.values())
        colors = plt.cm.Set3(np.linspace(0, 1, len(labels)))
        
        wedges, texts, autotexts = plt.pie(
            sizes, labels=labels, autopct='%1.1f%%',
            colors=colors, startangle=90
        )
        
        # Customize text
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontweight('bold')
        
        plt.title('Distribution of Predicted Dark Pattern Types', 
                 fontsize=16, fontweight='bold')
        plt.axis('equal')
        
        # Add legend
        plt.legend(wedges, [f'{label}: {count}' for label, count in pattern_counts.items()],
                  title="Pattern Types", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
        
        plt.tight_layout()
        plt.savefig('plots/research/shap/pattern_distribution.png', 
                   dpi=300, bbox_inches='tight')
        plt.savefig('plots/research/shap/pattern_distribution.pdf', 
                   bbox_inches='tight')
        plt.close()
    
    def plot_shap_heatmap(self, explanations):
        """Plot SHAP values heatmap"""
        plt.figure(figsize=(16, 10))
        
        # Prepare data for heatmap
        max_tokens = 20  # Limit to first 20 tokens for readability
        
        # Create matrix of SHAP values
        shap_matrix = []
        token_matrix = []
        
        for exp in explanations[:50]:  # Limit to 50 examples for readability
            tokens = exp['tokens'][:max_tokens]
            shap_values = exp['shap_values'][:max_tokens]
            
            # Pad with zeros if necessary
            while len(tokens) < max_tokens:
                tokens.append('')
                shap_values.append(0)
            
            token_matrix.append(tokens)
            shap_matrix.append(shap_values)
        
        # Create heatmap
        shap_array = np.array(shap_matrix)
        
        sns.heatmap(
            shap_array,
            xticklabels=[f'Token {i+1}' for i in range(max_tokens)],
            yticklabels=[f'Example {i+1}' for i in range(len(shap_matrix))],
            cmap='RdBu_r',
            center=0,
            cbar_kws={'label': 'SHAP Value'}
        )
        
        plt.title('SHAP Values Heatmap for Dark Pattern Detection', 
                 fontsize=16, fontweight='bold')
        plt.xlabel('Token Position', fontsize=12)
        plt.ylabel('Examples', fontsize=12)
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig('plots/research/shap/shap_heatmap.png', 
                   dpi=300, bbox_inches='tight')
        plt.savefig('plots/research/shap/shap_heatmap.pdf', 
                   bbox_inches='tight')
        plt.close()
    
    def save_explanations(self, explanations, filename='shap_explanations.json'):
        """Save SHAP explanations to file"""
        output_path = f'results/shap/{filename}'
        
        with open(output_path, 'w') as f:
            json.dump(explanations, f, indent=2)
        
        print(f"SHAP explanations saved to {output_path}")
    
    def generate_research_summary(self, explanations):
        """Generate research summary for paper"""
        summary = {
            'total_explanations': len(explanations),
            'pattern_distribution': {},
            'average_confidence': 0,
            'top_features': [],
            'analysis_timestamp': datetime.now().isoformat()
        }
        
        # Calculate pattern distribution
        pattern_counts = {}
        total_confidence = 0
        
        for exp in explanations:
            pattern = exp['predicted_class']
            pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1
            total_confidence += exp['confidence']
        
        summary['pattern_distribution'] = pattern_counts
        summary['average_confidence'] = total_confidence / len(explanations)
        
        # Get top features
        all_words = {}
        for exp in explanations:
            for word, score in exp['top_words']:
                if word in all_words:
                    all_words[word] += abs(score)
                else:
                    all_words[word] = abs(score)
        
        summary['top_features'] = sorted(all_words.items(), key=lambda x: x[1], reverse=True)[:10]
        
        # Save summary
        with open('results/shap/research_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
        
        return summary

def main():
    """Main function to run SHAP analysis"""
    
    # Initialize SHAP explainer
    explainer = EthicalEyeSHAPExplainer()
    
    # Sample texts for analysis
    sample_texts = [
        "Hurry! Only 2 left in stock!",
        "Join 10,000+ satisfied customers",
        "Limited time offer - expires soon!",
        "Free shipping on orders over $50",
        "Don't miss out on this exclusive deal",
        "Only 3 items remaining at this price",
        "Act now before it's too late!",
        "Welcome to our website",
        "Thank you for your purchase",
        "Contact us for support"
    ]
    
    # Generate explanations
    explanations = explainer.analyze_dataset(sample_texts)
    
    # Create plots
    explainer.create_shap_plots(explanations)
    
    # Save explanations
    explainer.save_explanations(explanations)
    
    # Generate research summary
    summary = explainer.generate_research_summary(explanations)
    
    print("\n" + "="*50)
    print("SHAP ANALYSIS COMPLETED!")
    print("="*50)
    print(f"Total explanations generated: {summary['total_explanations']}")
    print(f"Average confidence: {summary['average_confidence']:.3f}")
    print(f"Pattern distribution: {summary['pattern_distribution']}")
    print("\nTop features:")
    for word, score in summary['top_features'][:5]:
        print(f"  {word}: {score:.3f}")
    
    print("\nSHAP plots saved in: plots/research/shap/")
    print("Results saved in: results/shap/")

if __name__ == "__main__":
    main()
